{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friends_최종.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNGqxt5gOC7u2QpklXz2dxk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junghwanlee2019/2020Friends/blob/main/2019516019_%EC%9D%B4%EC%A0%95%ED%99%98_friends_%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6ootYP4Xlvh"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/gdrive') \r\n",
        "\r\n",
        "DATA_PATH = 'gdrive/My Drive/Colab Notebooks/'\r\n",
        "import sys\r\n",
        "sys.path.append(DATA_PATH)\r\n",
        "\r\n",
        "!pip install transformers --quiet # package installer for python\r\n",
        "\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "\r\n",
        "pretrained_weights = 'bert-large-uncased'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\r\n",
        "model = BertModel.from_pretrained(pretrained_weights)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BejxXqrdbo55"
      },
      "source": [
        "sentence = 'Finally I finished the project.'\r\n",
        "\r\n",
        "tokens = tokenizer.tokenize(sentence)\r\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]']\r\n",
        "print(tokens)\r\n",
        "\r\n",
        "ids = [tokenizer.convert_tokens_to_ids(tokens)]\r\n",
        "print(ids)\r\n",
        "input_tensor = torch.tensor(ids)\r\n",
        "print(input_tensor.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6WLO9nbq-m"
      },
      "source": [
        "hidden_tensor = model(input_tensor)[0]\r\n",
        "print(hidden_tensor.size())\r\n",
        "\r\n",
        "logit = torch.nn.Linear(1024, 2)(hidden_tensor)\r\n",
        "print(logit.size())\r\n",
        "print(logit.data)\r\n",
        "\r\n",
        "prediction = torch.nn.Softmax(dim=-1)(logit)\r\n",
        "print(prediction.size())\r\n",
        "print(prediction.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHYY_SqHbwSf"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "data = {'train': {'speaker': [], 'utterance': [], 'emotion': []},\r\n",
        "        'dev': {'speaker': [], 'utterance': [], 'emotion': []},\r\n",
        "        'test': {'speaker': [], 'utterance': [], 'emotion': []}}\r\n",
        "\r\n",
        "for dtype in ['train', 'dev', 'test']:\r\n",
        "  for dialog in json.loads(open(DATA_PATH + 'friends_' + dtype + '.json').read()):\r\n",
        "    for line in dialog:\r\n",
        "      data[dtype]['speaker'].append(line['speaker'])\r\n",
        "      data[dtype]['utterance'].append(line['utterance'])\r\n",
        "      data[dtype]['emotion'].append(line['emotion'])\r\n",
        "\r\n",
        "test_data = pd.read_csv(DATA_PATH + \"en_data.csv\", sep=',')\r\n",
        "\r\n",
        "e2i_dict = dict((emo, i) for i, emo in enumerate(set(data['train']['emotion'])))\r\n",
        "i2e_dict = {i: e for e, i in e2i_dict.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHBBgT_bz32"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.bert_tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\r\n",
        "    self.bert_model = BertModel.from_pretrained(pretrained_weights)\r\n",
        "    self.linear = torch.nn.Linear(1024, len(e2i_dict))\r\n",
        "\r\n",
        "  def forward(self, utterance):\r\n",
        "    tokens = self.bert_tokenizer.tokenize(utterance)\r\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]'] # (len)\r\n",
        "    ids = [tokenizer.convert_tokens_to_ids(tokens)] # (bat=1, len)\r\n",
        "    input_tensor = torch.tensor(ids).cuda()\r\n",
        "\r\n",
        "    hidden_tensor = self.bert_model(input_tensor)[0] # (bat, len, hid)\r\n",
        "    hidden_tensor = hidden_tensor[:, 0, :] # (bat, hid)\r\n",
        "    logit = self.linear(hidden_tensor)\r\n",
        "    return logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOLomnab1Nw"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "\r\n",
        "def evaluate(true_list, pred_list):\r\n",
        "  precision = precision_score(true_list, pred_list, average=None)\r\n",
        "  recall = recall_score(true_list, pred_list, average=None)\r\n",
        "  micro_f1 = f1_score(true_list, pred_list, average='micro')\r\n",
        "  print('precision:\\t', ['%.4f' % v for v in precision])\r\n",
        "  print('recall:\\t\\t', ['%.4f' % v for v in recall])\r\n",
        "  print('micro_f1: %.6f' % micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A80dxMJQcBxf"
      },
      "source": [
        "pretrained_weights = 'bert-large-uncased'\r\n",
        "learning_rate = 1e-6\r\n",
        "n_epoch = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FihhVxncEWe"
      },
      "source": [
        "import os\r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n",
        "import torch\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "\r\n",
        "model = Model()\r\n",
        "model.cuda()\r\n",
        "criterion = torch.nn.CrossEntropyLoss() # LogSoftmax & NLLLoss\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\r\n",
        "\r\n",
        "for i_epoch in range(n_epoch):\r\n",
        "  print('i_epoch:', i_epoch)\r\n",
        "\r\n",
        "  model.train()\r\n",
        "  for i_batch in tqdm_notebook(range(len(data['train']['utterance']))):\r\n",
        "    logit = model(data['train']['utterance'][i_batch])\r\n",
        "    target = torch.tensor([e2i_dict[data['train']['emotion'][i_batch]]]).cuda()\r\n",
        "    loss = criterion(logit, target)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "  \r\n",
        "  model.eval()\r\n",
        "  pred_list, true_list = [], []\r\n",
        "  for i_batch in tqdm_notebook(range(len(data['dev']['utterance']))):\r\n",
        "    logit = model(data['dev']['utterance'][i_batch])\r\n",
        "    _, max_idx = torch.max(logit, dim=-1)\r\n",
        "    pred_list += max_idx.tolist()\r\n",
        "    true_list += [e2i_dict[data['dev']['emotion'][i_batch]]]\r\n",
        "  evaluate(pred_list, true_list) # print results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKh7GxvRcGm_"
      },
      "source": [
        "final_result = []\r\n",
        "model.eval()\r\n",
        "pred_list, true_list = [], []\r\n",
        "for i_batch in tqdm_notebook(range(len(test_data['utterance']))):\r\n",
        "  id = test_data['id'][i_batch]\r\n",
        "  logit = model(test_data['utterance'][i_batch])\r\n",
        "  _, max_idx = torch.max(logit, dim=-1)\r\n",
        "  max_idx = int(max_idx.cpu().numpy())\r\n",
        "  \r\n",
        "  final_result.append([id , i2e_dict[max_idx]])\r\n",
        "\r\n",
        "final_result[:10]\r\n",
        "\r\n",
        "rdf = pd.DataFrame(final_result, columns =['Id', 'Expected'])\r\n",
        "rdf.to_csv(DATA_PATH + 'sample_eng_.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}